{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f1638be",
   "metadata": {},
   "source": [
    "In this dataset we are going to work on customer details, and will try to predict weather the customer has left the company or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00eda06",
   "metadata": {},
   "source": [
    "## Read & Observe Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec9433",
   "metadata": {},
   "source": [
    "/Users/dhanrajtentu/ds-projects/projects/01-customer-churn/code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12266f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ca37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b00128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b3be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some non necessary columns\n",
    "#df.drop(columns=['customerID','PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection', 'TechSupport','StreamingTV', 'StreamingMovies','PaymentMethod'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890aefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"customerID\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860051f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"{column}: {df[column].unique()}\")\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6c292",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the columns where the data is imbalance\n",
    "df.drop(columns=['gender','PhoneService','MultipleLines'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d368a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32349985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69caf32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3271aea",
   "metadata": {},
   "source": [
    "First we need to convert Yes No to int 0 or 1 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"{col} : {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13509b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to change the yes no to 1 or 0\n",
    "def convert_string_int(df):\n",
    "    accecpt = {'Yes', \"No\"}\n",
    "    #get the column names with only yes or no\n",
    "    yes_no_column = [col for col in df.columns\n",
    "                    if all(\n",
    "                        str(val).strip() in accecpt\n",
    "                        for val in df[col].unique()\n",
    "                    )]\n",
    "    to_int_dict = {'yes':1,'no' :0}\n",
    "    # change yes or no columns to 1 or 0\n",
    "    for col in yes_no_column:\n",
    "        df[col] = df[col].str.strip().str.lower().map(to_int_dict)\n",
    "        df[col] = df[col].astype(int)\n",
    "    accecpt_two = {'yes','no','no internet service'}\n",
    "    column_name_two = [col for col in df.columns\n",
    "                   if all(\n",
    "                       str(val).strip().lower() in accecpt_two\n",
    "                       for val in df[col].unique() \n",
    "                   )]\n",
    "    to_int_dict_two =  {'yes':1,'no' :0, 'no internet service':0}\n",
    "    for col in column_name_two:\n",
    "        df[col] = df[col].str.strip().str.lower().map(to_int_dict_two)\n",
    "        df[col] = df[col].astype(int)\n",
    "    return df    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_string_int(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a7439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned dataset\n",
    "df.to_csv(\"Churn_Cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d453629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf06082",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df, hue='Churn')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81023346",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(data=df.corr(numeric_only=True),annot=True, fmt= '.1f',cmap='crest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e69249e",
   "metadata": {},
   "source": [
    "## Feature Selection and Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebc3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Churn',axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "# train test spllit\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b8c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric features\n",
    "numeric_features = X.select_dtypes(int).columns.to_list()\n",
    "cat_features = X.select_dtypes(object).columns.to_list()\n",
    "numeric_features.append('MonthlyCharges') # append the only float columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and Encode the numeric and categorical columns respectively\n",
    "\n",
    "# scale numeric\n",
    "numeric_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "# onehot the categorical\n",
    "cat_transformer = Pipeline([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore',sparse_output=False,drop='first'))\n",
    "])\n",
    "\n",
    "# transform\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num',numeric_transformer,numeric_features),\n",
    "    ('cat',cat_transformer,cat_features)\n",
    "],remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd15404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef59a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced',\n",
    "    max_iter=500,\n",
    "    C=0.1,solver='lbfgs'),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    #\"GBosst\" : GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(name)\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocess', preprocessor),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)  \n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1] # get the probability\n",
    "    y_pred = (y_proba >= 0.40).astype(int) # reduce the probability to get more accurates churns\n",
    "\n",
    "   # print(f\"Accuracy Score   : {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"F1 Score         : {f1_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision Score  : {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"Recall Score: {recall_score(y_test,y_pred)}\")\n",
    "    print(f\"Confustion Matrix : \\n{confusion_matrix(y_test,y_pred)}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Churn\", \"Churn\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format='d')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e09a44",
   "metadata": {},
   "source": [
    "After tuning the model and after changing the parameters of logistic regression we got the highest recall score that is 0.87. As our data is trying to predict a bussiness, the false positives and false negatives should be considered and must be more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "800269af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipe,open(\"pipeline_churn.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bab086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
